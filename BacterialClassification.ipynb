{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZiOvsBSsTgYo"
   },
   "source": [
    "# Bacterial Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMuX8ZZgTgYo"
   },
   "source": [
    "## Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "sAdk6KqdTgYp",
    "outputId": "b5348b55-4b55-44f6-f4fc-ebbdcf447a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n",
      "/content/drive/My Drive/research/deep_learning/GDL_code\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "    \n",
    "%cd drive/My Drive/research/deep_learning/GDL_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8crIjTsYTgYs"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPAlDvwrTgYs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils.loaders import load_bacteria\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ks6HklBDTgYv"
   },
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sVv--YsiTgYv",
    "outputId": "8fb8115d-ff67-4ef7-b3af-e388c6f71aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will generate 250px square images.\n"
     ]
    }
   ],
   "source": [
    "# Generation resolution - Must be square \n",
    "# Training data is also scaled to this.\n",
    "GENERATE_SQUARE = 250\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = '/content/drive/My Drive/research/deep_learning/GDL_code/data/bacteria/'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")\n",
    "\n",
    "# run params\n",
    "SECTION = 'cnn'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'bacteria'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode = 'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FknPT4TYTgYx"
   },
   "source": [
    "## load & preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "GmwXjxopTgYy",
    "outputId": "7813d7bc-8267-4bb4-e967-251a259b1146"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file: /content/drive/My Drive/research/deep_learning/GDL_code/data/bacteria/bacteria_training_data_250_250.npy\n",
      "Loading training images...\n",
      "Saving training image binary...\n",
      "Image preprocess time: 0:00:00.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1a5b6f8d65a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test image loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Depending on size of image dataset, initial preprocessing can take a while.\n",
    "# Because of this time needed, save a Numpy preprocessed file.\n",
    "# In case this file is large enough to cause problems for some verisons of Pickle,\n",
    "# we use Numpy binary files instead.\n",
    "training_data = load_bacteria(DATA_PATH, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS, train=True)\n",
    "\n",
    "# test image loading\n",
    "plt.imshow(training_data[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCOBMAdqTgY0"
   },
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in training_data]).reshape(\n",
    "    -1, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
    "trainLabels = np.array([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jair_wwETgY2"
   },
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qm7IBKZiTgY2"
   },
   "outputs": [],
   "source": [
    "weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS), name='model_input')\n",
    "\n",
    "x = input_layer\n",
    "\n",
    "x = Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3, 3),\n",
    "    activation='relu',\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    kernel_initializer=weight_init)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(momentum=batch_norm_momentum)(x)\n",
    "\n",
    "x = Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    activation='relu',\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    kernel_initializer=weight_init)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(momentum=batch_norm_momentum)(x)\n",
    "\n",
    "x = Conv2D(\n",
    "    filters=96,\n",
    "    kernel_size=(3, 3),\n",
    "    activation='relu',\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    kernel_initializer=weight_init)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(momentum=batch_norm_momentum)(x)\n",
    "\n",
    "x = Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    activation='relu',\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    kernel_initializer=weight_init)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(momentum=batch_norm_momentum)(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu', kernel_initializer=weight_init)(x)\n",
    "x = Dropout(rate=0.4)(x)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_initializer=weight_init)(x)\n",
    "\n",
    "output_layer = Dense(2, activation='softmax', kernel_initializer=weight_init)(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6mJq8AWTgY5"
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ccqHQZfQTgY5"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8h9mLGVuTgY8"
   },
   "outputs": [],
   "source": [
    "model.fit(trainImages, trainLabels, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZOISiaKTgY9"
   },
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTh7VcQYTgY-"
   },
   "outputs": [],
   "source": [
    "# Depending on size of image dataset, initial preprocessing can take a while.\n",
    "# Because of this time needed, save a Numpy preprocessed file.\n",
    "# In case this file is large enough to cause problems for some verisons of Pickle,\n",
    "# we use Numpy binary files instead.\n",
    "test_data = load_bacteria(DATA_PATH, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS, train=False)\n",
    "plt.imshow(test_data[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9f1LHG4TgZA"
   },
   "outputs": [],
   "source": [
    "testImages = np.array([i[0] for i in test_data]).reshape(\n",
    "    -1, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
    "testLabels = np.array([i[1] for i in test_data])\n",
    "\n",
    "loss, acc = model.evaluate(testImages, testLabels, verbose=0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1-6HjeTTgZD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BacterialClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
