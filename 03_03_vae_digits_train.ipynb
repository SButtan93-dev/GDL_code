{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from models.VAE import VariationalAutoencoder\n",
    "from utils.loaders import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'digits'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 12s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(\n",
    "    input_dim = (28,28,1)\n",
    "    , encoder_conv_filters = [32,64,64, 64]\n",
    "    , encoder_conv_kernel_size = [3,3,3,3]\n",
    "    , encoder_conv_strides = [1,2,2,1]\n",
    "    , decoder_conv_t_filters = [64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 2\n",
    ")\n",
    "\n",
    "if mode == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 28, 28, 32)   0           encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 14, 14, 64)   18496       leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 14, 14, 64)   0           encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 64)     0           encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            6274        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            6274        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105,220\n",
      "Trainable params: 105,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/200\n",
      "   32/60000 [..............................] - ETA: 1:46:23 - loss: 231.7183 - vae_r_loss: 231.7178 - vae_kl_loss: 4.6890e-04WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.225436). Check your callbacks.\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 58.3881 - vae_r_loss: 55.1593 - vae_kl_loss: 3.2287\n",
      "Epoch 00001: saving model to run/vae/0002_digits/weights/weights-001-58.38.h5\n",
      "\n",
      "Epoch 00001: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 58.3826 - vae_r_loss: 55.1535 - vae_kl_loss: 3.2290\n",
      "Epoch 2/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 51.6212 - vae_r_loss: 47.6771 - vae_kl_loss: 3.9441\n",
      "Epoch 00002: saving model to run/vae/0002_digits/weights/weights-002-51.62.h5\n",
      "\n",
      "Epoch 00002: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 51.6182 - vae_r_loss: 47.6741 - vae_kl_loss: 3.9441\n",
      "Epoch 3/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 50.0823 - vae_r_loss: 45.8389 - vae_kl_loss: 4.2435\n",
      "Epoch 00003: saving model to run/vae/0002_digits/weights/weights-003-50.09.h5\n",
      "\n",
      "Epoch 00003: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 50.0857 - vae_r_loss: 45.8421 - vae_kl_loss: 4.2436\n",
      "Epoch 4/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 49.1659 - vae_r_loss: 44.7398 - vae_kl_loss: 4.4260\n",
      "Epoch 00004: saving model to run/vae/0002_digits/weights/weights-004-49.17.h5\n",
      "\n",
      "Epoch 00004: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 114s 2ms/sample - loss: 49.1684 - vae_r_loss: 44.7423 - vae_kl_loss: 4.4261\n",
      "Epoch 5/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 48.5699 - vae_r_loss: 44.0147 - vae_kl_loss: 4.5552\n",
      "Epoch 00005: saving model to run/vae/0002_digits/weights/weights-005-48.57.h5\n",
      "\n",
      "Epoch 00005: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 118s 2ms/sample - loss: 48.5704 - vae_r_loss: 44.0153 - vae_kl_loss: 4.5551\n",
      "Epoch 6/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 48.0902 - vae_r_loss: 43.4450 - vae_kl_loss: 4.6452\n",
      "Epoch 00006: saving model to run/vae/0002_digits/weights/weights-006-48.09.h5\n",
      "\n",
      "Epoch 00006: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 120s 2ms/sample - loss: 48.0895 - vae_r_loss: 43.4444 - vae_kl_loss: 4.6452\n",
      "Epoch 7/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 47.7231 - vae_r_loss: 43.0116 - vae_kl_loss: 4.7115\n",
      "Epoch 00007: saving model to run/vae/0002_digits/weights/weights-007-47.72.h5\n",
      "\n",
      "Epoch 00007: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 122s 2ms/sample - loss: 47.7230 - vae_r_loss: 43.0116 - vae_kl_loss: 4.7114\n",
      "Epoch 8/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 47.4386 - vae_r_loss: 42.6590 - vae_kl_loss: 4.7796\n",
      "Epoch 00008: saving model to run/vae/0002_digits/weights/weights-008-47.44.h5\n",
      "\n",
      "Epoch 00008: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 120s 2ms/sample - loss: 47.4371 - vae_r_loss: 42.6574 - vae_kl_loss: 4.7797\n",
      "Epoch 9/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 47.2004 - vae_r_loss: 42.3911 - vae_kl_loss: 4.8093\n",
      "Epoch 00009: saving model to run/vae/0002_digits/weights/weights-009-47.20.h5\n",
      "\n",
      "Epoch 00009: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 121s 2ms/sample - loss: 47.2034 - vae_r_loss: 42.3941 - vae_kl_loss: 4.8093\n",
      "Epoch 10/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.9456 - vae_r_loss: 42.0894 - vae_kl_loss: 4.8562\n",
      "Epoch 00010: saving model to run/vae/0002_digits/weights/weights-010-46.95.h5\n",
      "\n",
      "Epoch 00010: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 122s 2ms/sample - loss: 46.9467 - vae_r_loss: 42.0904 - vae_kl_loss: 4.8563\n",
      "Epoch 11/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.8023 - vae_r_loss: 41.9188 - vae_kl_loss: 4.8835\n",
      "Epoch 00011: saving model to run/vae/0002_digits/weights/weights-011-46.80.h5\n",
      "\n",
      "Epoch 00011: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 127s 2ms/sample - loss: 46.8018 - vae_r_loss: 41.9184 - vae_kl_loss: 4.8834\n",
      "Epoch 12/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.6021 - vae_r_loss: 41.6752 - vae_kl_loss: 4.9268\n",
      "Epoch 00012: saving model to run/vae/0002_digits/weights/weights-012-46.60.h5\n",
      "\n",
      "Epoch 00012: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 126s 2ms/sample - loss: 46.6050 - vae_r_loss: 41.6781 - vae_kl_loss: 4.9268\n",
      "Epoch 13/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.4656 - vae_r_loss: 41.5249 - vae_kl_loss: 4.9407\n",
      "Epoch 00013: saving model to run/vae/0002_digits/weights/weights-013-46.47.h5\n",
      "\n",
      "Epoch 00013: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 130s 2ms/sample - loss: 46.4651 - vae_r_loss: 41.5245 - vae_kl_loss: 4.9407\n",
      "Epoch 14/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.3129 - vae_r_loss: 41.3379 - vae_kl_loss: 4.9750\n",
      "Epoch 00014: saving model to run/vae/0002_digits/weights/weights-014-46.31.h5\n",
      "\n",
      "Epoch 00014: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 130s 2ms/sample - loss: 46.3129 - vae_r_loss: 41.3378 - vae_kl_loss: 4.9751\n",
      "Epoch 15/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.2210 - vae_r_loss: 41.2242 - vae_kl_loss: 4.9968\n",
      "Epoch 00015: saving model to run/vae/0002_digits/weights/weights-015-46.22.h5\n",
      "\n",
      "Epoch 00015: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 128s 2ms/sample - loss: 46.2217 - vae_r_loss: 41.2251 - vae_kl_loss: 4.9965\n",
      "Epoch 16/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 46.1034 - vae_r_loss: 41.0806 - vae_kl_loss: 5.0227\n",
      "Epoch 00016: saving model to run/vae/0002_digits/weights/weights-016-46.10.h5\n",
      "\n",
      "Epoch 00016: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 124s 2ms/sample - loss: 46.1018 - vae_r_loss: 41.0791 - vae_kl_loss: 5.0227\n",
      "Epoch 17/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 45.9840 - vae_r_loss: 40.9372 - vae_kl_loss: 5.0468\n",
      "Epoch 00017: saving model to run/vae/0002_digits/weights/weights-017-45.98.h5\n",
      "\n",
      "Epoch 00017: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 123s 2ms/sample - loss: 45.9811 - vae_r_loss: 40.9342 - vae_kl_loss: 5.0469\n",
      "Epoch 18/200\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 45.8682 - vae_r_loss: 40.8040 - vae_kl_loss: 5.0642\n",
      "Epoch 00018: saving model to run/vae/0002_digits/weights/weights-018-45.87.h5\n",
      "\n",
      "Epoch 00018: saving model to run/vae/0002_digits/weights/weights.h5\n",
      "60000/60000 [==============================] - 124s 2ms/sample - loss: 45.8693 - vae_r_loss: 40.8052 - vae_kl_loss: 5.0641\n",
      "Epoch 19/200\n",
      "19296/60000 [========>.....................] - ETA: 1:24 - loss: 45.9729 - vae_r_loss: 40.8846 - vae_kl_loss: 5.0882"
     ]
    }
   ],
   "source": [
    "vae.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (generative2)",
   "language": "python",
   "name": "generative2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
