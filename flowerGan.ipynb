{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "303iHntmdiDj"
   },
   "source": [
    "# FlowerGan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5n2iv9udiDk"
   },
   "source": [
    "\n",
    "\n",
    "This script takes flower images from this dataset:\n",
    "http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n",
    "\n",
    "and feeds it into a GAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gw7GCZxz6LQe"
   },
   "source": [
    "*Note, portions of this notebook are based on a [notebook from Jeff Heaton](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_Keras_gan.ipynb). Part of his [course](https://github.com/jeffheaton/t81_558_deep_learning) on Deep Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpCjlQyEdiDo"
   },
   "source": [
    "This code should be run on a GPU, it will be very slow on a CPU alone.  The following code mounts your Google drive for use with Google CoLab.  If you are not using CoLab, the following code will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Y8_-1h5ddiDp",
    "outputId": "ce0720c1-23f4-4e49-95ae-5d2729db15f3"
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "    \n",
    "%cd drive/My Drive/research/deep_learning/GDL_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FaZJOxe6LQm"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eD2EqZc26LQm"
   },
   "source": [
    "The following packages will be used to implement a basic GAN system in Python/Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KubxTY1mdiDm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_flowers, hms_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQcBSvyJ6LQp"
   },
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9uwIRYJdiDr"
   },
   "source": [
    "These are the constants that define how the GANs will be created for this example.  The higher the resolution, the more memory that will be needed.  Higher resolution will also result in longer run times.  For Google CoLab (with GPU) 128x128 resolution is as high as can be used (due to memory).  Note that the resolution is specified as a multiple of 32.  So **GENERATE_RES** of 1 is 32, 2 is 64, etc.\n",
    "\n",
    "To run this you will need training data.  The training data can be any collection of images.  I suggest using training data from the following two locations.  Simply unzip and combine to a common directory.  This directory should be uploaded to Google Drive (if you are using CoLab). The constant **DATA_PATH** defines where these images are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tb_XblE7diDr",
    "outputId": "38307d2d-5f32-4d0c-8f95-49f8d69b870e"
   },
   "outputs": [],
   "source": [
    "# Generation resolution - Must be square \n",
    "# Training data is also scaled to this.\n",
    "# Note GENERATE_RES 4 or higher  will blow Google CoLab's memory and have not\n",
    "# been tested extensivly.\n",
    "#GENERATE_RES = 3 # Generation resolution factor (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 128 #32 * GENERATE_RES # rows/cols (should be square)\n",
    "BLOCK_SQUARE = 450;\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = '/content/drive/My Drive/research/deep_learning/GDL_code/data/flower_gen'\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "#VIRTUAL_BATCH_SIZE = 16 # using virtual batch normalization\n",
    "#BUFFER_SIZE = 60000\n",
    "PRINT_EVERY_N_BATCHES = 5\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")\n",
    "\n",
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0003'\n",
    "DATA_NAME = 'flower_gen'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBqDzbaG6LQs"
   },
   "source": [
    "## load & preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDTfFQjTdiDu"
   },
   "source": [
    "Next we will load and preprocess the images.  This can take awhile.  Because of this we store the processed file as a binary.  This way we can simply reload the processed training data and quickly use it.  It is most efficient to only perform this operation once.  The dimensions of the image are encoded into the filename of the binary file because we need to regenerate it if these change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "id": "dJ69ALfSdiDv",
    "outputId": "16d37449-98e0-4343-ad31-d0eaecd24b31"
   },
   "outputs": [],
   "source": [
    "# Image set may have over 10000 images. Can take over an hour for initial preprocessing.\n",
    "# Because of this time needed, save a Numpy preprocessed file.\n",
    "# Note, that file is large enough to cause problems for some verisons of Pickle,\n",
    "# so Numpy binary files are used.\n",
    "training_data = load_flowers(\n",
    "    DATA_PATH, GENERATE_SQUARE, GENERATE_SQUARE, BLOCK_SQUARE, BLOCK_SQUARE, IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQrRX3oJ6LQv"
   },
   "source": [
    "## architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dATyXqQdiDw"
   },
   "source": [
    "The code below creates the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riYv1qvh6LQw"
   },
   "outputs": [],
   "source": [
    "gan = GAN(input_dim = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "        , discriminator_conv_filters = [64,64,128,128,256]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5,5]\n",
    "        , discriminator_conv_strides = [1,2,2,2,2]\n",
    "        , discriminator_batch_norm_momentum = 0.8\n",
    "        , discriminator_activation = 'leaky_relu'\n",
    "        , discriminator_dropout_rate = 0.4\n",
    "        , discriminator_learning_rate = 0.0002\n",
    "        , generator_initial_dense_layer_size = (8, 8, 256)\n",
    "        , generator_upsample = [2,2,2,2,1]\n",
    "        , generator_conv_filters = [256,128,128,64,IMAGE_CHANNELS]\n",
    "        , generator_conv_kernel_size = [5,5,5,5,5]\n",
    "        , generator_conv_strides = [1,1,1,1,1]\n",
    "        , generator_batch_norm_momentum = 0.8\n",
    "        , generator_activation = 'leaky_relu'\n",
    "        , generator_dropout_rate = 0.25\n",
    "        , generator_learning_rate = 0.00015\n",
    "        , optimiser = 'adam'\n",
    "        , z_dim = 100 # Size vector to generate images from (latent space)\n",
    "        , virtual_batch_size = None\n",
    "        , label_smoothing = 0.1\n",
    "        , preview_rows = 5 # Preview image\n",
    "        , preview_cols = 5 # Preview image\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvuyKj_66LQz"
   },
   "outputs": [],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94lF-O4F6LQ0"
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDBJQnlb6LQ1"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "gan.train(\n",
    "    training_data\n",
    "    , batch_size=BATCH_SIZE\n",
    "    , epochs=EPOCHS\n",
    "    , run_folder=RUN_FOLDER\n",
    "    , print_every_n_batches=PRINT_EVERY_N_BATCHES\n",
    ")\n",
    "\n",
    "elapsed = time.time()-start\n",
    "print (f'Training time: {hms_string(elapsed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15Hia_feD9sm"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hztPLRL86LQ6"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kT-0Cyxj6LQ8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "beautyGan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
