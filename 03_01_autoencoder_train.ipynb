{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"03_01_autoencoder_train.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CoyvhFVEtmia","colab_type":"text"},"source":["# Autoencoder"]},{"cell_type":"markdown","metadata":{"id":"HXAWlrBYtmic","colab_type":"text"},"source":["# Google Drive"]},{"cell_type":"code","metadata":{"id":"P4mxfW7Stmic","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"4ed9e9d6-c4a7-4305-fb35-3a8d59e38591","executionInfo":{"status":"ok","timestamp":1585800505452,"user_tz":240,"elapsed":23582,"user":{"displayName":"Carlos Castellanos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8rGO48v18uo_FvsgzSapfeYyImiOEsF-JuQtY=s64","userId":"10214169060280753218"}}},"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","    %tensorflow_version 2.x\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False\n","    \n","%cd drive/My Drive/projects/GDL_code"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Note: using Google CoLab\n","/content/drive/My Drive/projects/GDL_code\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PUSmRyCjtmif","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"WxVMB7QFtmif","colab_type":"code","colab":{}},"source":["import os\n","\n","from utils.loaders import load_mnist\n","from models.AE import Autoencoder"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DluydkNYtmih","colab_type":"text"},"source":["## Set parameters"]},{"cell_type":"code","metadata":{"id":"F16sim72tmii","colab_type":"code","colab":{}},"source":["# run params\n","SECTION = 'vae'\n","RUN_ID = '0001'\n","DATA_NAME = 'digits'\n","RUN_FOLDER = 'run/{}/'.format(SECTION)\n","RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n","\n","if not os.path.exists(RUN_FOLDER):\n","    os.mkdir(RUN_FOLDER)\n","    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n","    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n","    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n","\n","MODE =  'build' #'load' #"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpKT-JSctmik","colab_type":"text"},"source":["## Load the data"]},{"cell_type":"code","metadata":{"id":"kq2SeNcYtmik","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"fc01b260-f163-4358-9d31-66bed86fe618","executionInfo":{"status":"ok","timestamp":1585800531418,"user_tz":240,"elapsed":821,"user":{"displayName":"Carlos Castellanos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8rGO48v18uo_FvsgzSapfeYyImiOEsF-JuQtY=s64","userId":"10214169060280753218"}}},"source":["(x_train, y_train), (x_test, y_test) = load_mnist()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RMrrE7i6tmim","colab_type":"text"},"source":["## Define the structure of the neural network"]},{"cell_type":"code","metadata":{"id":"UPaMBAR9tmin","colab_type":"code","colab":{}},"source":["AE = Autoencoder(\n","    input_dim = (28,28,1)\n","    , encoder_conv_filters = [32,64,64, 64]\n","    , encoder_conv_kernel_size = [3,3,3,3]\n","    , encoder_conv_strides = [1,2,2,1]\n","    , decoder_conv_t_filters = [64,64,32,1]\n","    , decoder_conv_t_kernel_size = [3,3,3,3]\n","    , decoder_conv_t_strides = [1,2,2,1]\n","    , z_dim = 2\n",")\n","\n","if MODE == 'build':\n","    AE.save(RUN_FOLDER)\n","else:\n","    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vK_oYfjstmip","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"b9820055-545e-48d6-f013-e3f1863d68ee","executionInfo":{"status":"ok","timestamp":1585800609168,"user_tz":240,"elapsed":667,"user":{"displayName":"Carlos Castellanos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8rGO48v18uo_FvsgzSapfeYyImiOEsF-JuQtY=s64","userId":"10214169060280753218"}}},"source":["AE.encoder.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n","_________________________________________________________________\n","encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n","_________________________________________________________________\n","encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3136)              0         \n","_________________________________________________________________\n","encoder_output (Dense)       (None, 2)                 6274      \n","=================================================================\n","Total params: 98,946\n","Trainable params: 98,946\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mrambpzRtmir","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"outputId":"09b4c944-df82-4f0d-c093-36b36f747999","executionInfo":{"status":"ok","timestamp":1585800612663,"user_tz":240,"elapsed":368,"user":{"displayName":"Carlos Castellanos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8rGO48v18uo_FvsgzSapfeYyImiOEsF-JuQtY=s64","userId":"10214169060280753218"}}},"source":["AE.decoder.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","decoder_input (InputLayer)   [(None, 2)]               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 3136)              9408      \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n","_________________________________________________________________\n","leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n","_________________________________________________________________\n","decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n","_________________________________________________________________\n","activation (Activation)      (None, 28, 28, 1)         0         \n","=================================================================\n","Total params: 102,017\n","Trainable params: 102,017\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dvpGnvOGtmiu","colab_type":"text"},"source":["## Train the autoencoder"]},{"cell_type":"code","metadata":{"id":"g6K95rWMtmiu","colab_type":"code","colab":{}},"source":["LEARNING_RATE = 0.0005\n","BATCH_SIZE = 32\n","INITIAL_EPOCH = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wkr-m-lWtmiw","colab_type":"code","colab":{}},"source":["AE.compile(LEARNING_RATE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUYWyp12tmiy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5650c1b9-d9bb-4be7-c049-a8173e4fa015","executionInfo":{"status":"ok","timestamp":1585800699415,"user_tz":240,"elapsed":70889,"user":{"displayName":"Carlos Castellanos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8rGO48v18uo_FvsgzSapfeYyImiOEsF-JuQtY=s64","userId":"10214169060280753218"}}},"source":["AE.train(     \n","    x_train[:1000]\n","    , batch_size = BATCH_SIZE\n","    , epochs = 200\n","    , run_folder = RUN_FOLDER\n","    , initial_epoch = INITIAL_EPOCH\n",")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.2302WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.199965). Check your callbacks.\n","32/32 [==============================] - ETA: 0s - loss: 0.1634\n","Epoch 00001: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 1s 17ms/step - loss: 0.1634 - lr: 5.0000e-04\n","Epoch 2/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0748\n","Epoch 00002: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0740 - lr: 5.0000e-04\n","Epoch 3/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0674\n","Epoch 00003: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0672 - lr: 5.0000e-04\n","Epoch 4/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0645\n","Epoch 00004: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0644 - lr: 5.0000e-04\n","Epoch 5/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0614\n","Epoch 00005: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0610 - lr: 5.0000e-04\n","Epoch 6/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0595\n","Epoch 00006: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0591 - lr: 5.0000e-04\n","Epoch 7/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0569\n","Epoch 00007: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0574 - lr: 5.0000e-04\n","Epoch 8/200\n","31/32 [============================>.] - ETA: 0s - loss: 0.0559\n","Epoch 00008: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0557 - lr: 5.0000e-04\n","Epoch 9/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0546\n","Epoch 00009: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0545 - lr: 5.0000e-04\n","Epoch 10/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0541\n","Epoch 00010: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0540 - lr: 5.0000e-04\n","Epoch 11/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0533\n","Epoch 00011: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0535 - lr: 5.0000e-04\n","Epoch 12/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0528\n","Epoch 00012: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0529 - lr: 5.0000e-04\n","Epoch 13/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0521\n","Epoch 00013: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0522 - lr: 5.0000e-04\n","Epoch 14/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0517\n","Epoch 00014: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0520 - lr: 5.0000e-04\n","Epoch 15/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0512\n","Epoch 00015: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0510 - lr: 5.0000e-04\n","Epoch 16/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0508\n","Epoch 00016: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0509 - lr: 5.0000e-04\n","Epoch 17/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0504\n","Epoch 00017: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0506 - lr: 5.0000e-04\n","Epoch 18/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0501\n","Epoch 00018: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0504 - lr: 5.0000e-04\n","Epoch 19/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0498\n","Epoch 00019: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0499 - lr: 5.0000e-04\n","Epoch 20/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0494\n","Epoch 00020: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0496 - lr: 5.0000e-04\n","Epoch 21/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0492\n","Epoch 00021: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0491 - lr: 5.0000e-04\n","Epoch 22/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0491\n","Epoch 00022: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0488 - lr: 5.0000e-04\n","Epoch 23/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0490\n","Epoch 00023: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0490 - lr: 5.0000e-04\n","Epoch 24/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0484\n","Epoch 00024: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0485 - lr: 5.0000e-04\n","Epoch 25/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0487\n","Epoch 00025: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0481 - lr: 5.0000e-04\n","Epoch 26/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0485\n","Epoch 00026: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0480 - lr: 5.0000e-04\n","Epoch 27/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0480\n","Epoch 00027: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0478 - lr: 5.0000e-04\n","Epoch 28/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0480\n","Epoch 00028: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0480 - lr: 5.0000e-04\n","Epoch 29/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0473\n","Epoch 00029: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0473 - lr: 5.0000e-04\n","Epoch 30/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0473\n","Epoch 00030: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0473 - lr: 5.0000e-04\n","Epoch 31/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0561WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.132419). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0466\n","Epoch 00031: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0468 - lr: 5.0000e-04\n","Epoch 32/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0470\n","Epoch 00032: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0464 - lr: 5.0000e-04\n","Epoch 33/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0465\n","Epoch 00033: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0465 - lr: 5.0000e-04\n","Epoch 34/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0462\n","Epoch 00034: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0458 - lr: 5.0000e-04\n","Epoch 35/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0462\n","Epoch 00035: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0459 - lr: 5.0000e-04\n","Epoch 36/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0458\n","Epoch 00036: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0461 - lr: 5.0000e-04\n","Epoch 37/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0460\n","Epoch 00037: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0458 - lr: 5.0000e-04\n","Epoch 38/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0462\n","Epoch 00038: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0461 - lr: 5.0000e-04\n","Epoch 39/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0452\n","Epoch 00039: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0455 - lr: 5.0000e-04\n","Epoch 40/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0450\n","Epoch 00040: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0452 - lr: 5.0000e-04\n","Epoch 41/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0450\n","Epoch 00041: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0450 - lr: 5.0000e-04\n","Epoch 42/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0450\n","Epoch 00042: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0451 - lr: 5.0000e-04\n","Epoch 43/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0445\n","Epoch 00043: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0447 - lr: 5.0000e-04\n","Epoch 44/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0444\n","Epoch 00044: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0450 - lr: 5.0000e-04\n","Epoch 45/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0443\n","Epoch 00045: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0445 - lr: 5.0000e-04\n","Epoch 46/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0438\n","Epoch 00046: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0440 - lr: 5.0000e-04\n","Epoch 47/200\n","31/32 [============================>.] - ETA: 0s - loss: 0.0440\n","Epoch 00047: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0440 - lr: 5.0000e-04\n","Epoch 48/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0436\n","Epoch 00048: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0439 - lr: 5.0000e-04\n","Epoch 49/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0439\n","Epoch 00049: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0437 - lr: 5.0000e-04\n","Epoch 50/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0438\n","Epoch 00050: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0441 - lr: 5.0000e-04\n","Epoch 51/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0437\n","Epoch 00051: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0436 - lr: 5.0000e-04\n","Epoch 52/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0433\n","Epoch 00052: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0433 - lr: 5.0000e-04\n","Epoch 53/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0427\n","Epoch 00053: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0429 - lr: 5.0000e-04\n","Epoch 54/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0427\n","Epoch 00054: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0428 - lr: 5.0000e-04\n","Epoch 55/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0427\n","Epoch 00055: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0429 - lr: 5.0000e-04\n","Epoch 56/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0425\n","Epoch 00056: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0428 - lr: 5.0000e-04\n","Epoch 57/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0423\n","Epoch 00057: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0426 - lr: 5.0000e-04\n","Epoch 58/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0426\n","Epoch 00058: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0430 - lr: 5.0000e-04\n","Epoch 59/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0446WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.123402). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0425\n","Epoch 00059: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0424 - lr: 5.0000e-04\n","Epoch 60/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0424\n","Epoch 00060: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0426 - lr: 5.0000e-04\n","Epoch 61/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0422\n","Epoch 00061: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0420 - lr: 5.0000e-04\n","Epoch 62/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0422\n","Epoch 00062: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0426 - lr: 5.0000e-04\n","Epoch 63/200\n","31/32 [============================>.] - ETA: 0s - loss: 0.0423\n","Epoch 00063: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0423 - lr: 5.0000e-04\n","Epoch 64/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0421\n","Epoch 00064: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0418 - lr: 5.0000e-04\n","Epoch 65/200\n","27/32 [========================>.....] - ETA: 0s - loss: 0.0418\n","Epoch 00065: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0416 - lr: 5.0000e-04\n","Epoch 66/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0413\n","Epoch 00066: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0415 - lr: 5.0000e-04\n","Epoch 67/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0412\n","Epoch 00067: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0412 - lr: 5.0000e-04\n","Epoch 68/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0421WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.152711). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0411\n","Epoch 00068: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0416 - lr: 5.0000e-04\n","Epoch 69/200\n","27/32 [========================>.....] - ETA: 0s - loss: 0.0413\n","Epoch 00069: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0415 - lr: 5.0000e-04\n","Epoch 70/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0413\n","Epoch 00070: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0413 - lr: 5.0000e-04\n","Epoch 71/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0416\n","Epoch 00071: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0415 - lr: 5.0000e-04\n","Epoch 72/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0409\n","Epoch 00072: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0413 - lr: 5.0000e-04\n","Epoch 73/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0407\n","Epoch 00073: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0409 - lr: 5.0000e-04\n","Epoch 74/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0407\n","Epoch 00074: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0406 - lr: 5.0000e-04\n","Epoch 75/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0408\n","Epoch 00075: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0407 - lr: 5.0000e-04\n","Epoch 76/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0406\n","Epoch 00076: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0405 - lr: 5.0000e-04\n","Epoch 77/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0443WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.135556). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0405\n","Epoch 00077: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0404 - lr: 5.0000e-04\n","Epoch 78/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0403\n","Epoch 00078: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0404 - lr: 5.0000e-04\n","Epoch 79/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0402\n","Epoch 00079: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0401 - lr: 5.0000e-04\n","Epoch 80/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0401\n","Epoch 00080: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0403 - lr: 5.0000e-04\n","Epoch 81/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0401\n","Epoch 00081: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0403 - lr: 5.0000e-04\n","Epoch 82/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0399\n","Epoch 00082: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0402 - lr: 5.0000e-04\n","Epoch 83/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0403\n","Epoch 00083: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0402 - lr: 5.0000e-04\n","Epoch 84/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0398\n","Epoch 00084: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0401 - lr: 5.0000e-04\n","Epoch 85/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0397\n","Epoch 00085: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0400 - lr: 5.0000e-04\n","Epoch 86/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0397\n","Epoch 00086: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0397 - lr: 5.0000e-04\n","Epoch 87/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0394\n","Epoch 00087: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0393 - lr: 5.0000e-04\n","Epoch 88/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0391\n","Epoch 00088: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0392 - lr: 5.0000e-04\n","Epoch 89/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0394\n","Epoch 00089: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0393 - lr: 5.0000e-04\n","Epoch 90/200\n","27/32 [========================>.....] - ETA: 0s - loss: 0.0396\n","Epoch 00090: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0394 - lr: 5.0000e-04\n","Epoch 91/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0391\n","Epoch 00091: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0393 - lr: 5.0000e-04\n","Epoch 92/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0388\n","Epoch 00092: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0389 - lr: 5.0000e-04\n","Epoch 93/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0394\n","Epoch 00093: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0393 - lr: 5.0000e-04\n","Epoch 94/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0392\n","Epoch 00094: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0395 - lr: 5.0000e-04\n","Epoch 95/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0391\n","Epoch 00095: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0393 - lr: 5.0000e-04\n","Epoch 96/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0389\n","Epoch 00096: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0388 - lr: 5.0000e-04\n","Epoch 97/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0391\n","Epoch 00097: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0389 - lr: 5.0000e-04\n","Epoch 98/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0390\n","Epoch 00098: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0388 - lr: 5.0000e-04\n","Epoch 99/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0389\n","Epoch 00099: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0388 - lr: 5.0000e-04\n","Epoch 100/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0385\n","Epoch 00100: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0384 - lr: 5.0000e-04\n","Epoch 101/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0388\n","Epoch 00101: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0387 - lr: 5.0000e-04\n","Epoch 102/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0399\n","Epoch 00102: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0394 - lr: 5.0000e-04\n","Epoch 103/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0352WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.147040). Check your callbacks.\n","27/32 [========================>.....] - ETA: 0s - loss: 0.0387\n","Epoch 00103: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0387 - lr: 5.0000e-04\n","Epoch 104/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0387\n","Epoch 00104: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0387 - lr: 5.0000e-04\n","Epoch 105/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0383\n","Epoch 00105: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0383 - lr: 5.0000e-04\n","Epoch 106/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0386\n","Epoch 00106: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0381 - lr: 5.0000e-04\n","Epoch 107/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0381\n","Epoch 00107: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0383 - lr: 5.0000e-04\n","Epoch 108/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0384\n","Epoch 00108: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0383 - lr: 5.0000e-04\n","Epoch 109/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0380\n","Epoch 00109: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0382 - lr: 5.0000e-04\n","Epoch 110/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0381\n","Epoch 00110: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0382 - lr: 5.0000e-04\n","Epoch 111/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0380\n","Epoch 00111: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0382 - lr: 5.0000e-04\n","Epoch 112/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0381WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.131562). Check your callbacks.\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0378\n","Epoch 00112: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0378 - lr: 5.0000e-04\n","Epoch 113/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0380\n","Epoch 00113: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0380 - lr: 5.0000e-04\n","Epoch 114/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0383\n","Epoch 00114: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0380 - lr: 5.0000e-04\n","Epoch 115/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0379\n","Epoch 00115: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0378 - lr: 5.0000e-04\n","Epoch 116/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0378\n","Epoch 00116: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0377 - lr: 5.0000e-04\n","Epoch 117/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0383\n","Epoch 00117: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0379 - lr: 5.0000e-04\n","Epoch 118/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0379\n","Epoch 00118: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0375 - lr: 5.0000e-04\n","Epoch 119/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0376\n","Epoch 00119: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0376 - lr: 5.0000e-04\n","Epoch 120/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0366WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.141057). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0379\n","Epoch 00120: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0379 - lr: 5.0000e-04\n","Epoch 121/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0379\n","Epoch 00121: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0379 - lr: 5.0000e-04\n","Epoch 122/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0377\n","Epoch 00122: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0378 - lr: 5.0000e-04\n","Epoch 123/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0371\n","Epoch 00123: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0373 - lr: 5.0000e-04\n","Epoch 124/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0378\n","Epoch 00124: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0378 - lr: 5.0000e-04\n","Epoch 125/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0375\n","Epoch 00125: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0374 - lr: 5.0000e-04\n","Epoch 126/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0372\n","Epoch 00126: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0374 - lr: 5.0000e-04\n","Epoch 127/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0374\n","Epoch 00127: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0374 - lr: 5.0000e-04\n","Epoch 128/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0383\n","Epoch 00128: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0381 - lr: 5.0000e-04\n","Epoch 129/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0373\n","Epoch 00129: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0374 - lr: 5.0000e-04\n","Epoch 130/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0373\n","Epoch 00130: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0371 - lr: 5.0000e-04\n","Epoch 131/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0369\n","Epoch 00131: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0374 - lr: 5.0000e-04\n","Epoch 132/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0371\n","Epoch 00132: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0370 - lr: 5.0000e-04\n","Epoch 133/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0371\n","Epoch 00133: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0369 - lr: 5.0000e-04\n","Epoch 134/200\n","31/32 [============================>.] - ETA: 0s - loss: 0.0375\n","Epoch 00134: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0374 - lr: 5.0000e-04\n","Epoch 135/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0376\n","Epoch 00135: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0375 - lr: 5.0000e-04\n","Epoch 136/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0373\n","Epoch 00136: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0373 - lr: 5.0000e-04\n","Epoch 137/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0373\n","Epoch 00137: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0367 - lr: 5.0000e-04\n","Epoch 138/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0369\n","Epoch 00138: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0367 - lr: 5.0000e-04\n","Epoch 139/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0371\n","Epoch 00139: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0369 - lr: 5.0000e-04\n","Epoch 140/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0369\n","Epoch 00140: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0372 - lr: 5.0000e-04\n","Epoch 141/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0369\n","Epoch 00141: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0371 - lr: 5.0000e-04\n","Epoch 142/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0367\n","Epoch 00142: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0369 - lr: 5.0000e-04\n","Epoch 143/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0369\n","Epoch 00143: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0369 - lr: 5.0000e-04\n","Epoch 144/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0368\n","Epoch 00144: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0369 - lr: 5.0000e-04\n","Epoch 145/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0369\n","Epoch 00145: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0369 - lr: 5.0000e-04\n","Epoch 146/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0363\n","Epoch 00146: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0365 - lr: 5.0000e-04\n","Epoch 147/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0363\n","Epoch 00147: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0364 - lr: 5.0000e-04\n","Epoch 148/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0364\n","Epoch 00148: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0362 - lr: 5.0000e-04\n","Epoch 149/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0361\n","Epoch 00149: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - lr: 5.0000e-04\n","Epoch 150/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0367\n","Epoch 00150: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0367 - lr: 5.0000e-04\n","Epoch 151/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0362\n","Epoch 00151: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - lr: 5.0000e-04\n","Epoch 152/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0364\n","Epoch 00152: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0365 - lr: 5.0000e-04\n","Epoch 153/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0364\n","Epoch 00153: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0363 - lr: 5.0000e-04\n","Epoch 154/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0360WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.168934). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0361\n","Epoch 00154: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0365 - lr: 5.0000e-04\n","Epoch 155/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0357\n","Epoch 00155: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0361 - lr: 5.0000e-04\n","Epoch 156/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0362\n","Epoch 00156: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0362 - lr: 5.0000e-04\n","Epoch 157/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0370\n","Epoch 00157: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0371 - lr: 5.0000e-04\n","Epoch 158/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0363\n","Epoch 00158: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0365 - lr: 5.0000e-04\n","Epoch 159/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0365\n","Epoch 00159: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0362 - lr: 5.0000e-04\n","Epoch 160/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0362\n","Epoch 00160: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0363 - lr: 5.0000e-04\n","Epoch 161/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0363\n","Epoch 00161: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - lr: 5.0000e-04\n","Epoch 162/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0366\n","Epoch 00162: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0364 - lr: 5.0000e-04\n","Epoch 163/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0383WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.138092). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0358\n","Epoch 00163: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0359 - lr: 5.0000e-04\n","Epoch 164/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0365\n","Epoch 00164: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0359 - lr: 5.0000e-04\n","Epoch 165/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0364\n","Epoch 00165: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0359 - lr: 5.0000e-04\n","Epoch 166/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0359\n","Epoch 00166: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0360 - lr: 5.0000e-04\n","Epoch 167/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0360\n","Epoch 00167: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0360 - lr: 5.0000e-04\n","Epoch 168/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0356\n","Epoch 00168: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - lr: 5.0000e-04\n","Epoch 169/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0361\n","Epoch 00169: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0359 - lr: 5.0000e-04\n","Epoch 170/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0363\n","Epoch 00170: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0362 - lr: 5.0000e-04\n","Epoch 171/200\n","25/32 [======================>.......] - ETA: 0s - loss: 0.0357\n","Epoch 00171: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0359 - lr: 5.0000e-04\n","Epoch 172/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0360\n","Epoch 00172: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - lr: 5.0000e-04\n","Epoch 173/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0360\n","Epoch 00173: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0357 - lr: 5.0000e-04\n","Epoch 174/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0358\n","Epoch 00174: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0361 - lr: 5.0000e-04\n","Epoch 175/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0356\n","Epoch 00175: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0356 - lr: 5.0000e-04\n","Epoch 176/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0357\n","Epoch 00176: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0356 - lr: 5.0000e-04\n","Epoch 177/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0360\n","Epoch 00177: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - lr: 5.0000e-04\n","Epoch 178/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0358\n","Epoch 00178: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - lr: 5.0000e-04\n","Epoch 179/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0356\n","Epoch 00179: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0356 - lr: 5.0000e-04\n","Epoch 180/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0322WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.160946). Check your callbacks.\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0358\n","Epoch 00180: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0356 - lr: 5.0000e-04\n","Epoch 181/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0357\n","Epoch 00181: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0355 - lr: 5.0000e-04\n","Epoch 182/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0355\n","Epoch 00182: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0354 - lr: 5.0000e-04\n","Epoch 183/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0357\n","Epoch 00183: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0357 - lr: 5.0000e-04\n","Epoch 184/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0359\n","Epoch 00184: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0358 - lr: 5.0000e-04\n","Epoch 185/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0357\n","Epoch 00185: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0357 - lr: 5.0000e-04\n","Epoch 186/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0354\n","Epoch 00186: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0354 - lr: 5.0000e-04\n","Epoch 187/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0356\n","Epoch 00187: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0355 - lr: 5.0000e-04\n","Epoch 188/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0355\n","Epoch 00188: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0351 - lr: 5.0000e-04\n","Epoch 189/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0353\n","Epoch 00189: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0356 - lr: 5.0000e-04\n","Epoch 190/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0358\n","Epoch 00190: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0356 - lr: 5.0000e-04\n","Epoch 191/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0356\n","Epoch 00191: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0357 - lr: 5.0000e-04\n","Epoch 192/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0355\n","Epoch 00192: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0355 - lr: 5.0000e-04\n","Epoch 193/200\n","32/32 [==============================] - ETA: 0s - loss: 0.0357\n","Epoch 00193: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0357 - lr: 5.0000e-04\n","Epoch 194/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0352\n","Epoch 00194: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - lr: 5.0000e-04\n","Epoch 195/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0354\n","Epoch 00195: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - lr: 5.0000e-04\n","Epoch 196/200\n","30/32 [===========================>..] - ETA: 0s - loss: 0.0352\n","Epoch 00196: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0352 - lr: 5.0000e-04\n","Epoch 197/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0351\n","Epoch 00197: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0349 - lr: 5.0000e-04\n","Epoch 198/200\n"," 1/32 [..............................] - ETA: 0s - loss: 0.0352WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.105599). Check your callbacks.\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0348\n","Epoch 00198: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0353 - lr: 5.0000e-04\n","Epoch 199/200\n","28/32 [=========================>....] - ETA: 0s - loss: 0.0351\n","Epoch 00199: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0352 - lr: 5.0000e-04\n","Epoch 200/200\n","29/32 [==========================>...] - ETA: 0s - loss: 0.0354\n","Epoch 00200: saving model to run/vae/0001_digits/weights/weights.h5\n","32/32 [==============================] - 0s 8ms/step - loss: 0.0351 - lr: 5.0000e-04\n"],"name":"stdout"}]}]}